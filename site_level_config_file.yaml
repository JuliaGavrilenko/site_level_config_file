global_variables:
  - &spark_hadoop_master_ip_address 188.184.95.231
  - &spark_hadoop_master_fqdn spark-master.cern.ch
  - &spark_hadoop_worker_ip_address 188.184.104.92
  - &spark_hadoop_worker_fqdn spark-worker.cern.ch
  - &spark_hadoop_submit_ip_address 188.185.82.126
  - &spark_hadoop_submit_fqdn spark-submit.cern.ch

#spark_master_runtime_variables:
#  - &spark_master_runtime_var_host
#    __from__: *spark_hadoop_master_fqdn

#spark_worker_runtime_variables:
#  - &spark_worker_runtime_var_spark_master
#    __from__: *spark_hadoop_master_fqdn

#spark_submit_runtime_variables:
#  - &spark_submit_runtime_var_spark_master
#    __from__: *spark_hadoop_submit_fqdn

preferred_tech_stack:
  level_1_configuration: puppet
  level_2_configuration: sh
  container_orchestration: docker-swarm
  container: docker

site_infrastructure:
  - fqdn: *spark_hadoop_master_fqdn
    ip_address: *spark_hadoop_master_ip_address
  - fqdn: *spark_hadoop_worker_fqdn
    ip_address: *spark_hadoop_worker_ip_address
  - fqdn: *spark_hadoop_submit_fqdn
    ip_address: *spark_hadoop_submit_ip_address

lightweight_components:
  - type: spark_hadoop_master
    name: spark-hadoop-master
    repository_url: "https://github.com/maany/simple_spark_cluster_master"
    repository_revision: "master"
    execution_id: 0
    deploy:
      - node: *spark_hadoop_master_fqdn
        container_count: 1
    config:
        enable_init_daemon: false
#    supplemental_config:
#        "spark-defaults.conf":
#          - "spark.memory.fraction 0.75"
#          - "spark.executor.memory 1g"
#          - "spark.driver.cores 1"

  - name: spark-hadoop-worker
    type: spark_hadoop_worker
#    repository_url: "https://github.com/JuliaGavrilenko/spark_worker"
    repository_revision: "master"
    execution_id: 1
    deploy:
      - node: *spark_hadoop_worker_fqdn
        container_count: 1
    config:
        enable_init_daemon: false
        spark_master: *spark_hadoop_master_fqdn
#    supplemental_config:
#        "spark-defaults.conf":
#          - "spark.memory.fraction 0.75"
#          - "spark.executor.memory 1g"
#          - "spark.driver.cores 1"

  - name: spark-hadoop-submit
    type: spark_hadoop_submit
#    repository_url: "https://github.com/JuliaGavrilenko/spark_submit"
    repository_revision: "master"
    execution_id: 2
    deploy:
      - node: *spark_hadoop_submit_fqdn
        container_count: 1
    config:
        enable_init_daemon: false
#        spark_master: *spark_master_fqdn